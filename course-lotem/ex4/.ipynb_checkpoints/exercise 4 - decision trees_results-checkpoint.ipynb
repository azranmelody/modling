{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fzssrdQ6p9ec"
   },
   "source": [
    "## Making trees work - Exercise\n",
    "```In this exercise you will experience with Decision Trees and Random Forests. During this part you will explore the different features of them and will plot your results. Hence, whenever exploration tasks are marked with (*), know that you are asked to plot two graphs (on the same plot): the training score against the explored feature and the test score against it.```\n",
    "\n",
    "```~Ittai Haran```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BHCtFsfWp9ef"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y7a3_4Cxp9ek"
   },
   "source": [
    "```Read the dataset. In this dataset, you are provided over a hundred variables describing attributes of life insurance applicants. The task is to predict the \"Response\" variable.```\n",
    "\n",
    "```the dataset can be found in: ```https://drive.google.com/open?id=1t_P64gM1M1_c2n4PvH7AZoELH2CNh6ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vAp2cUCDp9el"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('insurance_fixed.csv')\n",
    "X = df.drop(['Response'], axis = 1)\n",
    "Y = df['Response']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size = 0.7, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vAp2cUCDp9el"
   },
   "outputs": [],
   "source": [
    "df['Response'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e3WxH3Xsp9ep"
   },
   "source": [
    "```We will start by using Decision trees. Use a simple DecisionTreeClassifier with default values to predict on your train and on your test. Evaluate the model using the accuracy metric, which you can find in sklearn.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AiB56h8rp9eq"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tgJAkBKNp9eu"
   },
   "outputs": [],
   "source": [
    "decision_tree_clf = DecisionTreeClassifier()\n",
    "decision_tree_clf.fit(X_train,Y_train)\n",
    "y_pred_test = decision_tree_clf.predict(X_test)\n",
    "y_pred_train = decision_tree_clf.predict(X_train)\n",
    "print('TEST ACCURACY : ' + str(accuracy_score(Y_test,y_pred_test)))\n",
    "print('TRAIN ACCURACY : ' + str(accuracy_score(Y_train,y_pred_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "606IhCe_p9ey"
   },
   "source": [
    "```Unfortunately, you are at overfit. Now let's try to get better. Try playing with the max depth of the tree, for``` $1\\leq depth \\leq25$ ```(*) (This means you are asked to plot some graphs, remember? :) )```\n",
    "\n",
    "```Choose the optimal max_depth based on the graph you got.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "exoVKRxpp9ez"
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameters={'max_depth': range(1,26)}\n",
    "# clf_tree=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "exoVKRxpp9ez"
   },
   "outputs": [],
   "source": [
    "# clf=GridSearchCV(clf_tree,parameters,scoring='accuracy')\n",
    "# clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "exoVKRxpp9ez"
   },
   "outputs": [],
   "source": [
    "# scores_df = pd.DataFrame(clf.cv_results_).sort_values(by='rank_test_score')\n",
    "# scores_df.head()\n",
    "\n",
    "#scores_df_for_plot = scores_df[['param_max_depth' , 'mean_test_score' , 'std_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "exoVKRxpp9ez"
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.lineplot(data = scores_df_for_plot, x='param_max_depth' , y='mean_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "exoVKRxpp9ez"
   },
   "outputs": [],
   "source": [
    "accuracy_train_test_by_depth = {}\n",
    "for i in range(1,26):\n",
    "    clf = DecisionTreeClassifier(max_depth=i).fit(X_train,Y_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    accuracy_train_test_by_depth[i] = (accuracy_score(Y_test,y_pred_test),accuracy_score(Y_train,y_pred_train))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "exoVKRxpp9ez"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(accuracy_train_test_by_depth , index=['test_accuracy' , 'train_accuracy']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "exoVKRxpp9ez"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.lineplot(data= df, x=df.index , y='test_accuracy')\n",
    "sns.lineplot(data= df, x=df.index , y='train_accuracy')\n",
    "plt.title('TRAIN-TEST ACCURACY BY MAX DEPTH PARAMETER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K1zQ3fa2p9e3"
   },
   "source": [
    "```Choose the best max_depth you found. Now try playing with min_samples_leaf. use the following values:\n",
    "[1, 10, 100, 300,700, 1000]. Do it also with max_depth = 20. What can we learn from the graphs? Please answer the question ```$\\ \\underline{in\\ another\\ cell}$```.(*)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ODRBOJmHp9e5"
   },
   "outputs": [],
   "source": [
    "df.sort_values(by='test_accuracy' , ascending=False) #it looks like the best depth for us is 8 - small difference betweem test & train with good accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ODRBOJmHp9e5"
   },
   "outputs": [],
   "source": [
    "#train with best deapth 8\n",
    "accuracy_train_test_by_min_samples_leaf = {}\n",
    "for i in [1, 10, 100, 300,700, 1000]:\n",
    "    clf = DecisionTreeClassifier(max_depth=8, min_samples_leaf=i).fit(X_train,Y_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    accuracy_train_test_by_min_samples_leaf[i] = (accuracy_score(Y_test,y_pred_test),accuracy_score(Y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ODRBOJmHp9e5"
   },
   "outputs": [],
   "source": [
    "df_min_samples_leaf = pd.DataFrame(accuracy_train_test_by_min_samples_leaf , index=['test_accuracy' , 'train_accuracy']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ODRBOJmHp9e5"
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data= df_min_samples_leaf, x=df_min_samples_leaf.index , y='test_accuracy' , legend='full', label='TEST')\n",
    "sns.lineplot(data= df_min_samples_leaf, x=df_min_samples_leaf.index , y='train_accuracy', legend='full', label='TRAIN')\n",
    "plt.title('TRAIN-TEST ACCURACY BY MIN SAMPLES LEAF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ODRBOJmHp9e5"
   },
   "outputs": [],
   "source": [
    "#from the graph above we can see that with the 'best' max_depth parameter (8) - the bigger the min sample leaf is than the accuracy reduces!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ODRBOJmHp9e5"
   },
   "outputs": [],
   "source": [
    "#train with best deapth 20\n",
    "accuracy_train_test_by_min_samples_leaf = {}\n",
    "for i in [1, 10, 100, 300,700, 1000]:\n",
    "    clf = DecisionTreeClassifier(max_depth=20, min_samples_leaf=i).fit(X_train,Y_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    accuracy_train_test_by_min_samples_leaf[i] = (accuracy_score(Y_test,y_pred_test),accuracy_score(Y_train,y_pred_train))\n",
    "    \n",
    "df_min_samples_leaf = pd.DataFrame(accuracy_train_test_by_min_samples_leaf , index=['test_accuracy' , 'train_accuracy']).T\n",
    "\n",
    "sns.lineplot(data= df_min_samples_leaf, x=df_min_samples_leaf.index , y='test_accuracy' , legend='full' , label='TEST')\n",
    "sns.lineplot(data= df_min_samples_leaf, x=df_min_samples_leaf.index , y='train_accuracy', legend='full', label='TRAIN')\n",
    "plt.title('TRAIN-TEST ACCURACY BY MIN SAMPLES LEAF')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ODRBOJmHp9e5"
   },
   "outputs": [],
   "source": [
    "#from the graph above we can see that using max_depth parameter to 20 - in the low values of min sample leaf there is a big overfitting, it starts to get balanced arount MIN_SAMPLES_LEAF=100 and above..but again - the bigger the min sample leaf is than the accuracy reduces!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G47JuWJyp9e9"
   },
   "source": [
    "```Decision Tree is a very nice algorithm, especially because it is very intuitive and explainable. We can even draw it!\n",
    "Train a simple Decision Tree with max_depth = 3. Call it basic_tree and run the cell below. Examine the file tree.png you created.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HwZ3WEzyp9e-"
   },
   "outputs": [],
   "source": [
    "basic_tree = DecisionTreeClassifier(max_depth=3).fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HwZ3WEzyp9e-"
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TdDoacrwp9fD"
   },
   "outputs": [],
   "source": [
    "# from sklearn.tree import export_graphviz\n",
    "# export_graphviz(basic_tree, out_file = 'tree.dot', filled  = True,\n",
    "#                 rounded = True, feature_names = X_train.columns)\n",
    "# !dot -Tpng tree.dot -o tree.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TdDoacrwp9fD"
   },
   "outputs": [],
   "source": [
    "Y_train_N = sorted(Y_train.unique())\n",
    "Y_train_N = list(map(str,Y_train_N))\n",
    "Y_train_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TdDoacrwp9fD"
   },
   "outputs": [],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TdDoacrwp9fD"
   },
   "outputs": [],
   "source": [
    "#sns.set_style(\"darkgrid\")\n",
    "import matplotlib as mpl\n",
    "from sklearn.tree import plot_tree\n",
    "#plt.style.use('dark_background')\n",
    "mpl.rcParams['text.color'] = 'black'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(40, 20), facecolor='b')\n",
    "plot_tree(basic_tree, rotate=True, ax=ax , fontsize=12 , feature_names=X_train.columns , class_names=Y_train_N)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o4lKwhgnp9fK"
   },
   "source": [
    "```Look at the tree you got. What, would you say, are the most important features?\n",
    "As you recall, we talked about feature importance in the lecture notes. Use the attribute feature_importance_ of your tree to get a list of the most important features.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ssS7KPYp9fM"
   },
   "outputs": [],
   "source": [
    "#the 10 most feature important\n",
    "pd.DataFrame(list(zip(basic_tree.feature_importances_,X_train.columns)) , columns=['value', 'feature_importance']).sort_values('value' ,ascending=False ).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HQvMNPvvp9fP"
   },
   "source": [
    "```We will now move to Random Forest. Repeat the exlporations tasks with a Random forest with 100 trees (max depth and min samples leaf). In addition, vary the number of trees between 10 and 400, while maintaining low max_depth (*) and the max_feature parameter, between 0.1 and 1 (*). Try explaining the graphs you see ```$\\ \\underline{in\\ a\\ different\\ cell}$```. Use the flag n_jobs = -1 in your experiments to accelerate your computation time. Make sure to understand where your model is overfitted.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9rw9Kqjp9fQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zjWk9kkUp9fW"
   },
   "outputs": [],
   "source": [
    "#EXPLORE MAX DEPTH AND SIMPLE LEAF - USING RANDOM FOREST WITH 100 TREES:\n",
    "\n",
    "accuracy_train_test_by_max_depth = {}\n",
    "for i in range(1,26):\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=i , n_jobs=-1).fit(X_train,Y_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    accuracy_train_test_by_max_depth[i] = (accuracy_score(Y_test,y_pred_test),accuracy_score(Y_train,y_pred_train))\n",
    "    \n",
    "df_max_depth = pd.DataFrame(accuracy_train_test_by_max_depth , index=['test_accuracy' , 'train_accuracy']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zjWk9kkUp9fW"
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data= df_max_depth, x=df_max_depth.index , y='test_accuracy' , legend='full' , label='TEST')\n",
    "sns.lineplot(data= df_max_depth, x=df_max_depth.index , y='train_accuracy', legend='full', label='TRAIN')\n",
    "plt.title('TRAIN-TEST ACCURACY BY MAX DEAPTH - WITH 100 TREES')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zjWk9kkUp9fW"
   },
   "outputs": [],
   "source": [
    "\n",
    "accuracy_train_test_by_min_samples_leaf = {}\n",
    "for i in [1, 10, 100, 300,700, 1000]:\n",
    "    clf = RandomForestClassifier(n_estimators=100, min_samples_leaf=i , n_jobs=-1).fit(X_train,Y_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    accuracy_train_test_by_min_samples_leaf[i] = (accuracy_score(Y_test,y_pred_test),accuracy_score(Y_train,y_pred_train))\n",
    "    \n",
    "df_min_samples_leaf = pd.DataFrame(accuracy_train_test_by_min_samples_leaf , index=['test_accuracy' , 'train_accuracy']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zjWk9kkUp9fW"
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data= df_min_samples_leaf, x=df_min_samples_leaf.index , y='test_accuracy' , legend='full' , label='TEST')\n",
    "sns.lineplot(data= df_min_samples_leaf, x=df_min_samples_leaf.index , y='train_accuracy', legend='full', label='TRAIN')\n",
    "plt.title('TRAIN-TEST ACCURACY BY MIN SAMPLES LEAF - WITH 100 TREES')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zjWk9kkUp9fW"
   },
   "outputs": [],
   "source": [
    "accuracy_train_test_by_num_of_trees = {}\n",
    "for i in range(10,401):\n",
    "    clf = RandomForestClassifier(n_estimators=i, max_depth=5 , n_jobs=-1).fit(X_train,Y_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    accuracy_train_test_by_num_of_trees[i] = (accuracy_score(Y_test,y_pred_test),accuracy_score(Y_train,y_pred_train))\n",
    "    \n",
    "df_num_of_trees = pd.DataFrame(accuracy_train_test_by_num_of_trees , index=['test_accuracy' , 'train_accuracy']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zjWk9kkUp9fW"
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data= df_num_of_trees, x=df_num_of_trees.index , y='test_accuracy' , legend='full' , label='TEST')\n",
    "sns.lineplot(data= df_num_of_trees, x=df_num_of_trees.index , y='train_accuracy', legend='full', label='TRAIN')\n",
    "plt.title('TRAIN-TEST ACCURACY BY NUMBER OF TREE WITH LOW DEPTH(5)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "yiBm0FYKp9fa"
   },
   "outputs": [],
   "source": [
    "df_num_of_trees.sort_values(by='test_accuracy' , ascending=False) #i will choose 30 tree for the next question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "yiBm0FYKp9fa"
   },
   "outputs": [],
   "source": [
    "#max_feature\n",
    "\n",
    "accuracy_train_test_by_max_feature = {}\n",
    "for i in np.arange(0.1,1.1,0.1):\n",
    "    clf = RandomForestClassifier(n_estimators=5,max_features=i, n_jobs=-1).fit(X_train,Y_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    accuracy_train_test_by_max_feature[i] = (accuracy_score(Y_test,y_pred_test),accuracy_score(Y_train,y_pred_train))\n",
    "    \n",
    "df_max_feature = pd.DataFrame(accuracy_train_test_by_max_feature , index=['test_accuracy' , 'train_accuracy']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "yiBm0FYKp9fa"
   },
   "outputs": [],
   "source": [
    "df_max_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "yiBm0FYKp9fa"
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data= df_max_feature, x=df_max_feature.index , y='test_accuracy' , legend='full' , label='TEST')\n",
    "sns.lineplot(data= df_max_feature, x=df_max_feature.index , y='train_accuracy', legend='full', label='TRAIN')\n",
    "plt.title('TRAIN-TEST ACCURACY BY MAX FEATURE')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yiBm0FYKp9fa"
   },
   "source": [
    "```As you could see, at least one of your graphs turned out to be very noisy. Use K Fold cross validation to evalute your model more accurately. In K Fold cross validation we split our data into K segments, and for each ```$\\ 1\\leq i\\leq K\\ $``` we test our model on the i-th segment while training it using the others.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aNUFKqLnp9fb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aNUFKqLnp9fb"
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1) \n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': range(10,401)\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 2, refit=True,n_jobs=-1, scoring='accuracy' , verbose=5) #using cross validation = 2 because it takes too much time..\n",
    "\n",
    "re = grid_search_rf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aNUFKqLnp9fb"
   },
   "outputs": [],
   "source": [
    "grid_results_df = pd.DataFrame(re.cv_results_)\n",
    "grid_results_df.sort_values(by='mean_test_score' , ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aNUFKqLnp9fb"
   },
   "outputs": [],
   "source": [
    "re.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aNUFKqLnp9fb"
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.lineplot(data=grid_results_df , x='param_n_estimators' ,y='mean_test_score')\n",
    "#sns.lineplot(data=grid_results_df , x='param_n_estimators' ,y='std_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aNUFKqLnp9fb"
   },
   "outputs": [],
   "source": [
    "re.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aNUFKqLnp9fb"
   },
   "outputs": [],
   "source": [
    "test_preds = re.best_estimator_.predict(X_test)\n",
    "train_preds = re.best_estimator_.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aNUFKqLnp9fb"
   },
   "outputs": [],
   "source": [
    "accuracy_score(Y_test,test_preds),accuracy_score(Y_train,train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aNUFKqLnp9fb"
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# kf = KFold(n_splits=3) # Define the split - into 2 folds \n",
    "# kf.get_n_splits(X_train,Y_train) # returns the number of splitting iterations in the cross-validator\n",
    "# print(kf) \n",
    "\n",
    "# KFold(n_splits=2, random_state=None, shuffle=False)\n",
    "\n",
    "# for train_index, test_index in kf.split(X_train):\n",
    "#     #print('TRAIN:', train_index, 'TEST:', test_index)\n",
    "#     #print(Y_train.iloc[test_index])\n",
    "    \n",
    "#     accuracy_train_test_by_num_of_trees = {}\n",
    "#     for i in range(10,401):\n",
    "        \n",
    "#         clf = RandomForestClassifier(n_estimators=i, max_depth=5 , n_jobs=-1).fit(X_train.iloc[train_index] , Y_train.iloc[train_index])\n",
    "#         y_pred_test = clf.predict(X_train.iloc[test_index])\n",
    "#         y_pred_train = clf.predict(X_train.iloc[train_index])\n",
    "#         accuracy_train_test_by_num_of_trees[i] = (accuracy_score(Y_train.iloc[test_index],y_pred_test),accuracy_score(Y_train.iloc[train_index],y_pred_train))\n",
    "    \n",
    "#     df_num_of_trees = pd.DataFrame(accuracy_train_test_by_num_of_trees , index=['test_accuracy' , 'train_accuracy']).T\n",
    "    \n",
    "#     sns.lineplot(data= df_num_of_trees, x=df_num_of_trees.index , y='test_accuracy' , legend='full' , label='TEST')\n",
    "#     sns.lineplot(data= df_num_of_trees, x=df_num_of_trees.index , y='train_accuracy', legend='full', label='TRAIN')\n",
    "#     plt.title('TRAIN-TEST ACCURACY BY NUMBER OF TREE WITH LOW DEPTH(5)')\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aNUFKqLnp9fb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tGhmyNw0p9fj"
   },
   "source": [
    "## Extra thinking on feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PbXXU8wHp9fl"
   },
   "source": [
    "```We talked about feature importance in the lecture notes. get the feature importance of each feature using a decision tree and using a random forest. Use in both cases the best hyper parameters you found so far. Discuss the differences between the answers``` $\\underline{in\\ a\\ cell}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5YWe7OXHp9fn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hG6DkTTJp9fs"
   },
   "source": [
    "```We can define a concept of feature importance for linear regression: Suppose you have two features, ```$x_1$ ```and``` $x_2$. ```Suppose that you got a linear regression of the form```\n",
    "\n",
    "$y = 100\\cdot x_1 + 1\\cdot x_2$\n",
    "\n",
    "```What feature is more important? What if we have -100 instead of 100? Generalize this idea to any number of features. Train a linear regression on your data and get the feature importances.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qfyUj613p9fu"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JC7giU7Qp9fz"
   },
   "outputs": [],
   "source": [
    "#Feature importance is calculated as the decrease in node impurity weighted by the probability of reaching that node. The node probability can be calculated by the number of samples that reach the node, divided by the total number of samples. The higher the value the more important the feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EVpv87ulp9f3"
   },
   "source": [
    "## Ensemble methods and stacking\n",
    "```In this part we will explore the concept of model stacking: that is, training a model, the combining model, on the outputs of several other models. Hence, the stacking method has two steps: first we train our models, and than we train the combining model using the outputs of those models.```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7VTlcjE7p9f4"
   },
   "source": [
    "```In the setting of stacking models it is very important to train the several models on one segment of the data and train the combining model on another segment. Hence, start by splitting the data to 3 segments: train_1 segment, 35% of the data, train_2 segment, 35% of the data, and test segment, the last 30% of the data.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vwZliyTSp9f5"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size = 0.7, test_size = 0.3)\n",
    "\n",
    "X_train_1, X_train_2 ,Y_train_1, Y_train_2 = train_test_split(X_train, Y_train, train_size = 0.5, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vwZliyTSp9f5"
   },
   "outputs": [],
   "source": [
    "int(len(X)*0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vwZliyTSp9f5"
   },
   "outputs": [],
   "source": [
    "t1 = X[:20783]\n",
    "t1_y = Y[:20783]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vwZliyTSp9f5"
   },
   "outputs": [],
   "source": [
    "t2 = X[20783: 20783*2]\n",
    "t2_y = Y[20783: 20783*2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vwZliyTSp9f5"
   },
   "outputs": [],
   "source": [
    "test = X[20783*2 :]\n",
    "test_y = Y[20783*2 :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vwZliyTSp9f5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f4vnyD6dp9f8"
   },
   "source": [
    "```Our first experiment is as follows: train a random forest of simple decision trees (30 trees, max_depth = 3), using train_1. Use the estimators of the forest to create 30*8=240 features: for each estimator get the probabilities it gives for the target to belong to any of the classes. You can get the list of the estimators using RandomForestClassifier.estimators_ and have the probabilities mentioned using model.predict_proba.\n",
    "Using the new features you got (and them only), train a logistic regression (LogisticRegression).\n",
    "Compare between the accuracy of the first random forest (on the test segment) and the accuracy of the stacked models (again, on the test segment).```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Hqn9a7Dp9f9"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjVZ-Ne9p9gC"
   },
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=30, max_depth=3).fit(t1,t1_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjVZ-Ne9p9gC"
   },
   "outputs": [],
   "source": [
    "# for index,clf_dicision_tree in enumerate(clf_rf.estimators_):\n",
    "#     print(index,clf_dicision_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjVZ-Ne9p9gC"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "#dict_proba = {}\n",
    "for index,clf_dicision_tree in enumerate(clf_rf.estimators_[:]):\n",
    "    probabilities=[]\n",
    "    probabilities = clf_rf.estimators_[index].predict_proba(t2.reset_index(drop=True))\n",
    "    x = pd.DataFrame(probabilities)\n",
    "    #print(x)\n",
    "    x.rename(columns=lambda x: 'TREE:'  + str(index+1) +'_CLASS:' + str(x+1), inplace=True)\n",
    "    if (index==0):\n",
    "        df = x\n",
    "    else:\n",
    "        df = pd.concat([df,x] , axis=1)\n",
    "                  \n",
    "    #print(clf_dicision_tree.predict_proba(X_train_2))\n",
    "    #dict_proba[index] = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjVZ-Ne9p9gC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjVZ-Ne9p9gC"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjVZ-Ne9p9gC"
   },
   "outputs": [],
   "source": [
    "t2_y = t2_y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjVZ-Ne9p9gC"
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame()\n",
    "#dict_proba = {}\n",
    "for index,clf_dicision_tree in enumerate(clf_rf.estimators_[:]):\n",
    "    probabilities=[]\n",
    "    probabilities = clf_rf.estimators_[index].predict_proba(test.reset_index(drop=True))\n",
    "    x = pd.DataFrame(probabilities)\n",
    "    #print(x)\n",
    "    x.rename(columns=lambda x: 'TREE:'  + str(index+1) +'_CLASS:' + str(x+1), inplace=True)\n",
    "    if (index==0):\n",
    "        df_test = x\n",
    "    else:\n",
    "        df_test = pd.concat([df_test,x] , axis=1)\n",
    "                  \n",
    "    #print(clf_dicision_tree.predict_proba(X_train_2))\n",
    "    #dict_proba[index] = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjVZ-Ne9p9gC"
   },
   "outputs": [],
   "source": [
    "test_y = test_y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjVZ-Ne9p9gC"
   },
   "outputs": [],
   "source": [
    "clf_lr = LogisticRegression().fit(df,t2_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjVZ-Ne9p9gC"
   },
   "outputs": [],
   "source": [
    "test_preds = clf_lr.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjVZ-Ne9p9gC"
   },
   "outputs": [],
   "source": [
    "accuracy_score(test_y,test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjVZ-Ne9p9gC"
   },
   "outputs": [],
   "source": [
    "train_preds= clf_lr.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjVZ-Ne9p9gC"
   },
   "outputs": [],
   "source": [
    "train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjVZ-Ne9p9gC"
   },
   "outputs": [],
   "source": [
    "accuracy_score(t2_y,train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjVZ-Ne9p9gC"
   },
   "outputs": [],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b7hRZrXnp9gG"
   },
   "source": [
    "```We will conduct a similar experiment: create a set of at least 5 different models, of different kinds - use algorithms we talked about in the course. Stack them to get a better model. Compare the accuracies of the models to the accuracy of your stacked model.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LJN0tyBqp9gI"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegressionCV, LogisticRegression, RidgeClassifier, RidgeClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ur5FBy-1p9gL"
   },
   "outputs": [],
   "source": [
    "clf1 = DecisionTreeClassifier().fit(X_train_1,Y_train_1)\n",
    "clf2 = KNeighborsClassifier().fit(X_train_1,Y_train_1)\n",
    "clf3 = LogisticRegression()\n",
    "clf3.fit(X_train_1,Y_train_1)\n",
    "clf4 = RidgeClassifier()\n",
    "clf4.fit(X_train_1,Y_train_1)\n",
    "clf5 = RidgeClassifierCV()\n",
    "clf5.fit(X_train_1,Y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ur5FBy-1p9gL"
   },
   "outputs": [],
   "source": [
    "#every classifier predictions seperatly:\n",
    "\n",
    "clf1_preds = clf1.predict(X_test)\n",
    "print(accuracy_score(Y_test,clf1_preds))\n",
    "\n",
    "clf2_preds = clf2.predict(X_test)\n",
    "print(accuracy_score(Y_test,clf2_preds))\n",
    "\n",
    "clf3_preds = clf3.predict(X_test)\n",
    "print(accuracy_score(Y_test,clf3_preds))\n",
    "\n",
    "clf4_preds = clf4.predict(X_test)\n",
    "print(accuracy_score(Y_test,clf4_preds))\n",
    "\n",
    "clf5_preds = clf5.predict(X_test)\n",
    "print(accuracy_score(Y_test,clf5_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ur5FBy-1p9gL"
   },
   "outputs": [],
   "source": [
    "# Voting Classifier with soft voting \n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ur5FBy-1p9gL"
   },
   "outputs": [],
   "source": [
    "votingC = VotingClassifier(estimators=[('clf1', clf1),('clf2', clf2),('clf3', clf3),('clf4', clf4),('clf5', clf5)], voting='hard')\n",
    "votingC = votingC.fit(X_train_2, Y_train_2)\n",
    "predict_y = votingC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ur5FBy-1p9gL"
   },
   "outputs": [],
   "source": [
    "accuracy_score(Y_test,predict_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eCU_NVUp9gP"
   },
   "source": [
    "```As we said earlier, it is very important use two different train segments. What happens if you use the same train segment in both steps of the stacked model? Note that you now use more data to train your models, and also your combining model. Do you get better results? Do it and explain your results ```$\\underline{\\ in\\ a\\ cell\\ below.}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1EEYQWXVp9gR"
   },
   "outputs": [],
   "source": [
    "# #CHECK\n",
    "# votingC = VotingClassifier(estimators=[('clf1', clf1),('clf2', clf2),('clf3', clf3),('clf4', clf4),('clf5', clf5)], voting='hard')\n",
    "# votingC = votingC.fit(X_train_1, Y_train_1)\n",
    "# predict_y = votingC.predict(X_test)\n",
    "\n",
    "# accuracy_score(Y_test,predict_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we use the same training data for the weak learners and the combination the model will be less general and can be overfitted"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "exercise 2 - supervised learning (and some clustering).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
