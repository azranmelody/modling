{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature extraction exercise\n",
    "```This exercise is purely about features extraction. We will learn how to do it quick and efficiently.\n",
    "We will be working on a kaggle dataset of quora questions, where each record is composed of a pair of questions, while the target is to determine whether the questions have the same meaning.\n",
    "We will extract features for each question and for each pair of questions and will train a simple model (default xgboost) using those features.```\n",
    "\n",
    "```The purpose of this exercise is to acquire good practices, so please read the instructions carefully and do as it says. You are also encouraged to look at the solution when after you are finished. In addition, when solving the exercise, try to write\n",
    "as efficient and as clean code as you can.```\n",
    "\n",
    "```Note: We are about to do some kaggle cheats, that is, we will compute features by mixing the train and the test.\n",
    "Please notice exactly where we did so. In addition, every time you meet a question in the instructions (you can identify a question by '?'), please answer it in a comment block. ```\n",
    "\n",
    "```~Ittai Haran```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some modules you might find useful\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "import re\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence tokenizer for future use\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "twt_tokenizer = TweetTokenizer()\n",
    "\n",
    "# word2vec model for future use\n",
    "\n",
    "## can be found in: https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\n",
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('D:\\Download\\GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('D:/Download/quora-question-pairs/train.csv') \n",
    "data.head()\n",
    "data = data.iloc[:2000]\n",
    "data = data[data.apply(lambda x: not (type(x['question1']) == float or type(x['question2']) == float), axis = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```First we would like to extract features regarding a single question. In order to do so, first create a dataset containing  all the questions (and their id. why should we remember the id?), without duplicates. Name it 'questions'.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = data[['qid1','question1']].rename(columns={'question1' : 'question' ,'qid1':'qID' })\n",
    "q2 = data[['qid2','question2']].rename(columns={'question2' : 'question' ,'qid2':'qID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union= pd.concat([q1, q2]).drop_duplicates()\n",
    "df_union['question'] = df_union['question'].str.lower() #low case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union = df_union.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Add a column containing the questions, tokenized using twt_tokenizer, the TweetTokenizer object we created earlier. Name it 'question_sep'. Make sure that you treat the questions in lower case.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union['question_sep'] = df_union.apply(lambda x: twt_tokenizer.tokenize(x['question']) , axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Create an empty list called 'question_features_for_future_use'. We are going to befoul the questions dataframe, so we will want to remember which of its columns are important to us and which are just columns helping us to create other columns.```\n",
    "```Next, I will ask you to create some features. Whenever I use this sign: (*), know that you have to add the feature name to the list.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_features_for_future_use = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Before we start computing features, write a function that gets a column name and saves a csv file with 2 columns: qid and the column chosen. Name it 'save_feature' and make sure you use it after every feature computed, since it might be very very important for later parts of the exercise and your life.```\n",
    "\n",
    "```Save the features in the resources/features/<col_name>.csv .```\n",
    "\n",
    "```use os.path and os.getcwd().```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_col_toCSV(col_name , df=df_union):\n",
    "    df.to_csv(index=False , columns=['qID' , col_name] , path_or_buf='resources/features/' + col_name + '.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Compute the following:```\n",
    "- ```Counter of the word part of speech (use collections.Counter and pos_tag, which we imported earlier. do it using one line). (*)```\n",
    "- ```number of different numbers appearing in the question\n",
    "(numbers, not digits. use regex. don't count words like 'one') (one line). (*)```\n",
    "- ```number of words in a question (one line). (*)```\n",
    "- ```length of longest word (one line). (*)```\n",
    "- ```word2vec mean of the question. (*)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union['part_of_speech_counter'] = df_union.apply(lambda x : Counter([j for i,j in pos_tag(word_tokenize(x['question']))]) , axis=1)\n",
    "question_features_for_future_use.append('part_of_speech_counter') # (*)\n",
    "save_col_toCSV('part_of_speech_counter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union['number_of_numbers'] = df_union.apply(lambda x : len([int(word) for word in x['question'].split(sep=' ') if word.isdigit()]) , axis=1)\n",
    "question_features_for_future_use.append('number_of_numbers') # (*)\n",
    "save_col_toCSV('number_of_numbers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union['number_of_words'] = df_union.apply(lambda x: len(x['question_sep']) - 1 , axis=1) #minus 1 beacuse i dont want to count the question mark.\n",
    "question_features_for_future_use.append('number_of_words') # (*)\n",
    "save_col_toCSV('number_of_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union['length_of_longest_word'] =df_union['question_sep'].apply(lambda x: max(len(s) for s in x))\n",
    "question_features_for_future_use.append('length_of_longest_word') # (*)\n",
    "save_col_toCSV('length_of_longest_word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec.wv[df_union.iloc[0]['question_sep'][8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_mean_of_question(row):\n",
    "    sum_vector =0\n",
    "    count =0\n",
    "    for i in row['question_sep']:\n",
    "              if i in (word2vec.vocab.keys()):\n",
    "                sum_vector = sum_vector + word2vec.wv[i]\n",
    "                count = count + 1\n",
    "\n",
    "    avg_vec = sum_vector / count\n",
    "    return word2vec.most_similar(positive=[avg_vec], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union['word2vec_mean_of_question']=df_union.apply(word2vec_mean_of_question , axis=1).apply(lambda x : [y[0] for y in list(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union['word2vec_mean_of_question'] = df_union['word2vec_mean_of_question'].str.join(', ')\n",
    "question_features_for_future_use.append('word2vec_mean_of_question') # (*)\n",
    "save_col_toCSV('word2vec_mean_of_question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_features_for_future_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```Counter of the question_words (one line). (*)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_words = ['why', 'how', 'where', 'who', 'what', 'which', 'when', 'wheather']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union['counter_question_words'] = df_union['question_sep'].apply(lambda x: sum(x.count(z) for z in question_words))\n",
    "question_features_for_future_use.append('counter_question_words') # (*)\n",
    "save_col_toCSV('counter_question_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```We will now use tf-idf grade (if you aren't familiar with the concept, read about it;) ``` https://en.wikipedia.org/wiki/Tf%E2%80%93idf ```).\n",
    "do the following:```\n",
    "- ```initialize a TfidfVectorizer object. use norm = None, use English stop words and twt_tokenizer we used before. Name it tfidf.```\n",
    "- ```create the tf-idf matrix of all the questions (look again at the note in the beginning of the exercise).```\n",
    "- ```look at tfidf.vocabulary_.```\n",
    "- ```create a reversed vocabulary (given an index returns a word. do it in one line, using list comprehension).```\n",
    "- ```create a column, such that every question has a list of its words and the word's tf-idf grades. do it without transferring the tf-idf matrix into a dense matrix (keep it sparse).```\n",
    "- ```for each question, find the third biggest tf-idf grade. create a column such that every question have a list of the words with bigger grades the the third biggest tf-idf grade. (*)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twt_tokenizer.tokenize,norm=None, stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = tfidf.fit_transform(df_union['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(score.toarray(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_voc = tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_vocabulary   = { original_voc[k]:k for k in original_voc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverse_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union['words_and_tfidf_grade'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper =[]\n",
    "for i in range(len(df_union)):\n",
    "    helper = dict(df.iloc[i][df.iloc[i]!=0])\n",
    "    df_union.loc[i , 'words_and_tfidf_grade'] = [helper]\n",
    "    helper = []\n",
    "    #print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union['th3_biggest_tfidf']   = np.NaN\n",
    "for i in range(len(df_union)):\n",
    "    if(len(df_union.iloc[i]['words_and_tfidf_grade']) >2):\n",
    "        keys_highest = sorted(df_union.iloc[i]['words_and_tfidf_grade'], key=df_union.iloc[i]['words_and_tfidf_grade'].get, reverse=True)[2:3]\n",
    "        th3_biggest = {k:df_union.iloc[i]['words_and_tfidf_grade'][k] for k in df_union.iloc[i]['words_and_tfidf_grade'].keys() if df_union.iloc[i]['words_and_tfidf_grade'][k]>=df_union.iloc[i]['words_and_tfidf_grade'][keys_highest[0]]}\n",
    "    else:\n",
    "        th3_biggest = df_union.iloc[i]['words_and_tfidf_grade']\n",
    "    df_union.loc[i , 'th3_biggest_tfidf'] = [th3_biggest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_features_for_future_use.append('th3_biggest_tfidf') # (*)\n",
    "save_col_toCSV('th3_biggest_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"question_features_for_future_use.txt\", question_features_for_future_use, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```We will do it again, this time more general, by completing the following functions.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T09:06:23.696008Z",
     "start_time": "2019-09-05T09:06:23.689988Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_tuple = [(k, v) for k, v in df_union.iloc[4]['words_and_tfidf_grade'].items()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T09:06:23.696008Z",
     "start_time": "2019-09-05T09:06:23.689988Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_most_important_words_n(x, n = 3):\n",
    "    # the function gets a list of tuples (word, tf-idf grade) and n\n",
    "    # it returns the words which have grades bigger than the n'th biggest grade. Note that several words may have the same grade.\n",
    "    if (len(x)<=3):\n",
    "        return x\n",
    "    else:\n",
    "        x = sorted(x, key=lambda x: x[1] , reverse=True)    \n",
    "        third_biggest_value =x[n-1]\n",
    "        result = list(filter(lambda y: y[1]>=third_biggest_value[1] , x))\n",
    "\n",
    "    return result\n",
    "    \n",
    "\n",
    "def get_most_important_words_total(x, n = 3):\n",
    "    if (len(x)<=3):\n",
    "        return x\n",
    "    else:\n",
    "        x = sorted(x, key=lambda x: x[1] , reverse=True)\n",
    "        \n",
    "    return x[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_features(n_gram, most_important_words_method):\n",
    "    # the function gets the size of n for the n_grams in the tf-idf computation and\n",
    "    # the result method, which will be one of the two functions above\n",
    "    # it adds the tf-idf features you computed before\n",
    "    # when n_gram = 1, make the function add another feature: the mean word2vec vector of the most important words\n",
    "    # features created will be added to question_features_for_future_use (!)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_most_important_words_n(list_of_tuple,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_most_important_words_total(list_of_tuple,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tfidf_features(1,get_most_important_words_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tfidf_features(2,partial(get_most_important_words_total, n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```We now move to features concerning both questions, and not just one of them. But first, run the following cell, known as the evil cell.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(''.join(map(lambda x: chr(ord(x)-1), 'fyju)*'))+'\\n'\\\n",
    "     +''.join(map(lambda x: chr(ord(x)-1), 'qsjou)#Ibibibib!J!fyjufe!zpvs!lfsofm/!Dpoujovf!gspn!ifsf'+\\\n",
    "                  '!xjuipvu!sfsvoojoh!uif!qsfwjpvt!dfmmt!)cftjeft!uif!jnqpsu!dfmmt-!boe!mpbe!uif!ebub!bhbjo*#*'))\\\n",
    "    +'\\n'+''.join(map(lambda x: chr(ord(x)-1), 'jnqpsu!nbuqmpumjc/qzqmpu!bt!qmu\\x0bgspn!nbuqmpumjc/jnbhf!jnqpsu!jnsfbe\\x0bjnb'+\\\n",
    "                      'hf!>!jnsfbe)#sftpvsdft0wjtvbmj{bujpo!ifmqfst0T'+\\\n",
    "                      'njmjoh`Efwjm`Fnpkj/qoh#*\\x0bqmu/jntipx)jnbhf*\\x0bqmu/tipx)*')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Understand how the evil cell works.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it killed my kernel :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Now we will add the features we computed earlier to the data dataframe. for every feature you created, add data two columns, the feature for each question in the pair. Use DataFrame.merge and the qid columns you saved every time you saved a feature. Use also os.listdir and DataFrame.rename, and do it in 7 lines of code at top.\n",
    "Use the following converter (in the pd.read_csv syntax): converters = {feature_name:lambda x: eval(x)}. Why is it needed? Hint: open pos_tag_count.csv. If you aren't familiar with the amazing eval function, read about it:)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the eval is needed for keep some of the types (for example the Counter) , because the default is to keep it as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_features_for_future_use = np.loadtxt('question_features_for_future_use.txt' , dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ DATA FROM CSV's\n",
    "for index,feat in enumerate(question_features_for_future_use):\n",
    "    feature_from_csv = pd.read_csv('resources/features/'+feat+'.csv')\n",
    "    if (index==0):\n",
    "        all_features_to_add = pd.read_csv('resources/features/'+feat+'.csv' , converters={feat:lambda x: eval(x)}) \n",
    "    else: \n",
    "        \n",
    "        all_features_to_add = all_features_to_add.merge(feature_from_csv, on='qID' , how='inner' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_to_add_Q1 =  all_features_to_add[all_features_to_add['qID']%2!=0] # DATA FOR Q1\n",
    "all_features_to_add_Q2 =  all_features_to_add[all_features_to_add['qID']%2==0] # DATA FOR Q2\n",
    "\n",
    "all_features_to_add_Q1.columns = [str(col) + '_Q1' for col in all_features_to_add_Q1.columns]\n",
    "all_features_to_add_Q2.columns = [str(col) + '_Q2' for col in all_features_to_add_Q2.columns]\n",
    "\n",
    "data_extend = data.merge(all_features_to_add_Q1 , left_on='qid1' , right_on='qID_Q1')\n",
    "data_extend = data_extend.merge(all_features_to_add_Q2 , left_on='qid2' , right_on='qID_Q2' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_extend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_to_add_Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_data = data_extend.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Now we would like to find a way to take a feature for each question separately and make it one. Remember our question features are of 3 kinds:```\n",
    "- ```number```\n",
    "- ```Counter```\n",
    "- ```vector```\n",
    "\n",
    "```For each kind we will write a method taking both features and producing one feature:```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_two_features_to_1_number(number_1, number_2):\n",
    "    # the function returns |number_1-number_2|\n",
    "    return abs(number_1-number_2)\n",
    "    \n",
    "\n",
    "def from_two_features_to_1_vector(vector_1, vector_2):  #>>>>>>>>>>>>>>>>>>>>>>>>>i convert the mean vector back to word format, thats why i will calculate the similarity by words.\n",
    "    # the function returns the cosine similarity between the vectors\n",
    "    similarity =  word2vec.similarity(vector_1,vector_2)\n",
    "    return similarity\n",
    "    \n",
    "\n",
    "def from_two_features_to_1_counter(counter_1, counter_2):\n",
    "    # the Counter objects represent distribution. return the sim of all absolute values of differences between them.\n",
    "    # Remember- Counter have some great properties.\n",
    "    R1 = {k: min(v, counter_2[k]) for k, v in counter_1.items()}\n",
    "    R2 = {k: abs(v - counter_2[k]) for k, v in counter_1.items()}\n",
    "    return sum(R2.values())\n",
    "    \n",
    "\n",
    "def from_two_features_to_1(feature_1, feature_2):\n",
    "    # return the right one feature based on the feature's types\n",
    "    if((copy_data[feature_1].dtype == np.int64) & (copy_data[feature_2].dtype == np.int64 )):\n",
    "        copy_data['diff_between_' + feature_1[:-3] ] = copy_data.apply(lambda x: from_two_features_to_1_number(x[feature_1], x[feature_2]) , axis=1)\n",
    "    if( (type(copy_data.iloc[0][feature_1]) == np.str )& (type(copy_data.iloc[0][feature_2]) == np.str )):\n",
    "        print('helloo')\n",
    "        copy_data['similarity_between_' + feature_1[:-3] ] = copy_data.apply(lambda x: from_two_features_to_1_vector(x[feature_1], x[feature_2]) , axis=1)\n",
    "    if((str(type(copy_data.iloc[0][feature_1])) == \"<class 'collections.Counter'>\" ) & (str(type(copy_data.iloc[0][feature_2])) == \"<class 'collections.Counter'>\" )):\n",
    "        copy_data['sum_diff_' + feature_1[:-3] ] = copy_data.apply(lambda x: from_two_features_to_1_counter(x[feature_1], x[feature_2]) , axis=1)\n",
    "        \n",
    "    return copy_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_data = from_two_features_to_1('number_of_words_Q1','number_of_words_Q2')\n",
    "copy_data = from_two_features_to_1('number_of_numbers_Q1','number_of_numbers_Q2')\n",
    "copy_data = from_two_features_to_1('length_of_longest_word_Q1','length_of_longest_word_Q2')\n",
    "copy_data = from_two_features_to_1('counter_question_words_Q1','counter_question_words_Q2')\n",
    "\n",
    "copy_data = from_two_features_to_1('word2vec_mean_of_question_Q1','word2vec_mean_of_question_Q2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_data = from_two_features_to_1('part_of_speech_counter_Q1','part_of_speech_counter_Q2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```I suspect you know what that's for:```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features_for_future_use = copy_data\n",
    "data_features_for_future_use.to_csv(index=False , path_or_buf='resources/features/data_features_for_future_use.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Use the methods you wrote to get one feature from every pair of features you have, while running over the features in question_features_for_future_use. give it meaningful names.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#already did it :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Add the following features:```\n",
    "- ```number of common words between the two questions. (one line) (*)```\n",
    "- ```number of common words between the two questions, not including stop words. (one line) (*)```\n",
    "\n",
    "```You might have to use twt_tokenizer again. note that we could save the tikenized questions.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T14:21:47.684219Z",
     "start_time": "2019-09-05T14:21:47.670220Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of common words between the two questions.\n",
    "copy_data['number_of_common_words'] =  copy_data.apply(lambda x : len(set(x['question1'].split()) & set(x['question2'].split())) , axis=1)\n",
    "copy_data['number_of_common_words_without_stopwords'] =  copy_data.apply(lambda x : len(set(x['question1'].split()) & set(x['question2'].split()) - stop_words) , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Now think of a feature of your own and implement it.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def both_containing_parenthesis(feature1, feature2):\n",
    "    result1 = any(c=='(' for c in feature1) & any(c==')' for c in feature1) \n",
    "    result2 = any(c=='(' for c in feature2) & any(c==')' for c in feature2) \n",
    "    if(result1==True & result2==True):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_data['both_containing_parenthesis'] =  copy_data.apply(lambda x : both_containing_parenthesis(x['question1'] , x['question2']) , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```I'm not going to use the evil cell again, but I'll remind you to save your features.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_data.to_csv(index=False , path_or_buf='resources/features/data_features_for_future_use.csv' ) #saved it all..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```That's it! take your features and train a RandomForestRegressor using them. Don't forget to split to train and test sections. What score did you get?```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_objects = []\n",
    "for col in copy_data.columns:\n",
    "    if copy_data[col].dtypes != \"O\":\n",
    "        non_objects.append(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_model = copy_data[non_objects]\n",
    "df_for_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_for_model['is_duplicate']\n",
    "df_for_model = df_for_model.drop('is_duplicate', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and testing vars\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_for_model, labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(min_samples_leaf=20 , max_depth=8)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = clf.predict(X_test)\n",
    "preds_train = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
