{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression - Excercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```In this exercise you will experience with simple features of the linear and logistic regressions, and will get to know some interesting features of those regressions.```\n",
    "\n",
    "~```Ittai Haran```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficients and some more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```We will start by exploring several concepts regarding linear and logistic regression. To that matter, we will prefer working using a generated dataset. Start by generating (using numpy and np.random) the following dataset:```\n",
    "\n",
    "$X \\sim \\cal N(0,1)^3$ ```(i.e X consists of 3-dimensional vectors)```\n",
    "\n",
    "$Y = 0.3\\cdot X[:,0] + 0.5\\cdot X[:,1] - 0.7\\cdot X[:,2] + 1$\n",
    "\n",
    "```Generate 1,000 samples.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(0,1 , size=(1000, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = X[:,0] + 0.5*X[:,1]-0.7*X[:,2] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Train a simple linear regression (sklearn.linear_model.LinearRegression) on the data. What coefficients did you get using your regression? Did you expect those coefficients?```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearRegression()\n",
    "clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3 , figsize=(20,5))\n",
    "for i in range(3):\n",
    "    sns.scatterplot(X[:,i], Y, ax=axes[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_ # the coefs are expcted according to the plots above (up, nomal and down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```We will now conduct a similar experiment, only this time using logistic regression, with minor adjustments:```\n",
    "\n",
    "$X \\sim \\cal N(0,1)^3$ ```(i.e X consists of 3-dimensional vectors)```\n",
    "\n",
    "$Y = (0.3\\cdot X[:,0] + 0.5\\cdot X[:,1] - 0.7\\cdot X[:,2] \\geq 1)$\n",
    "\n",
    "```Generate 1,000 samples.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(0,1 , size=(1000, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = (X[:,0] + 0.5*X[:,1]-0.7*X[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,item in enumerate(Y):\n",
    "    if (item>1):\n",
    "        Y[idx]=1\n",
    "    else:\n",
    "        Y[idx]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Train a simple logistic regression (sklearn.linear_model.LogisticRegression) on the data. What coefficients did you get using your logistic regression? Did you expect those coefficients? Why, or why not?```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.DataFrame(index= [X[:,0],X[:,1],X[:,2],Y]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3 , figsize=(20,5))\n",
    "for i in range(3):\n",
    "    sns.scatterplot(X[:,i], Y, ax=axes[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3 , figsize=(20,5))\n",
    "sns.regplot(x='level_0', y='level_3', data=df, logistic=True , ax=axes[0])\n",
    "sns.regplot(x='level_1', y='level_3', data=df, logistic=True , ax=axes[1])\n",
    "sns.regplot(x='level_2', y='level_3', data=df, logistic=True , ax=axes[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Repeat this experiment, this time with 10,000 samples and 100,000 samples. Did you get different coefficients? Why or why not?```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(0,1 , size=(10000, 3))\n",
    "\n",
    "Y = (X[:,0] + 0.5*X[:,1]-0.7*X[:,2])\n",
    "\n",
    "for idx,item in enumerate(Y):\n",
    "    if (item>1):\n",
    "        Y[idx]=1\n",
    "    else:\n",
    "        Y[idx]=0\n",
    "        \n",
    "clf = LogisticRegression()\n",
    "clf.fit(X,Y)\n",
    "\n",
    "df  = pd.DataFrame(index= [X[:,0],X[:,1],X[:,2],Y]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3 , figsize=(20,5))\n",
    "sns.regplot(x='level_0', y='level_3', data=df, logistic=True , ax=axes[0])\n",
    "sns.regplot(x='level_1', y='level_3', data=df, logistic=True , ax=axes[1])\n",
    "sns.regplot(x='level_2', y='level_3', data=df, logistic=True , ax=axes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(0,1 , size=(100000, 3))\n",
    "\n",
    "Y = (X[:,0] + 0.5*X[:,1]-0.7*X[:,2])\n",
    "\n",
    "for idx,item in enumerate(Y):\n",
    "    if (item>1):\n",
    "        Y[idx]=1\n",
    "    else:\n",
    "        Y[idx]=0\n",
    "        \n",
    "clf = LogisticRegression()\n",
    "clf.fit(X,Y)\n",
    "\n",
    "df  = pd.DataFrame(index= [X[:,0],X[:,1],X[:,2],Y]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3 , figsize=(20,5))\n",
    "sns.regplot(x='level_0', y='level_3', data=df, logistic=True , ax=axes[0])\n",
    "sns.regplot(x='level_1', y='level_3', data=df, logistic=True , ax=axes[1])\n",
    "sns.regplot(x='level_2', y='level_3', data=df, logistic=True , ax=axes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['level_3'].value_counts() #there are much more zeros than ones. thats why the plots looks like this and the coefs also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear linear regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Load the data in func_1_train.csv.\n",
    "Can be found in: https://drive.google.com/open?id=1y3HtVk0N1q4xYn_qczDcdkZfGpy23z9l```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('func_1_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Draw a scatter plot of y as a function of x. What kind of functions would you like to fit here?```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(df['x'] , df['y'])\n",
    "plt.show() #it should not be a linear model.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Try fitting a linear regression. Draw the data points and the function you fitted on the same plot.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearRegression()\n",
    "clf.fit(df[['x']], df[['y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = clf.predict(df[['x']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(df['y'], Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(df['x'] , df['y'])\n",
    "sns.scatterplot(df['x'] , Y_pred[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Let's do some feature extraction. Create a dataset with the features (X, X**2, X**3, ..., X**49). Now try fitting a linear regression using your new dataset. Draw your results on the same graph as before. Judge your results using func_1_test and using the mean squared error metric.```\n",
    "\n",
    "```Can be found in: https://drive.google.com/open?id=1ipm09QTjVZWFgh-zc70rxWLGPWYEt1Kb```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('func_1_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature extraction for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,x in enumerate(df['x'] , start=2):\n",
    "    if(idx>49):\n",
    "        break\n",
    "    df['x'+str(idx)] = np.power(df['x'],idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature extraction for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,x in enumerate(df_test['x'] , start=2):\n",
    "    if(idx>49):\n",
    "        break\n",
    "    df_test['x'+str(idx)] = np.power(df_test['x'],idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['y']\n",
    "X_train = df.drop('y' , axis=1)\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train , target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = clf.predict(X_train)\n",
    "Y_pred_test = clf.predict(df_test.drop('y' , axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(df_test['x'] , Y_pred_test)\n",
    "sns.scatterplot(df_test['x'] , df_test['y'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(df_test['y'], Y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```How come you could a model that isn't under fitted? You did still use a linear regression. Can you explain those results? However, your model seemed to be over fitted (why?). Why is that?```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer: it is indeed a lineal regression but we have much more features here, each one has an influence on the predictions thats why it is more complicated model after all. the model is overfitted bacause the values on the train are similar to the test's value and again, many features \n",
    "# and small dataset.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```You can try using a regularized regression to avoid over fitting. Use sklearn.linear_model.Ridge with different alphas until you get nice fit (judge it using your plots and using func_1_test and the mean squared error metric). Could you get better results?```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Ridge(alpha=1.5)\n",
    "clf.fit(X_train , target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = clf.predict(df_test.drop('y' , axis=1))\n",
    "\n",
    "sns.scatterplot(df_test['x'] , Y_pred_test)\n",
    "sns.scatterplot(df_test['x'] , df_test['y'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(df_test['y'], Y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on a real life data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Start by loading house_data.csv. For our current purposes we will need only the numeric columns. Take only the numeric columns, using pandas.DataFrame.dtypes. Use fillna(0) to get rid of nans (the the column Id. can tell why?).```\n",
    "\n",
    "```Can be found in: https://drive.google.com/open?id=1ID2h8mzjXLRbay5pE0QN1v5-jc86203L```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('house_data.csv')\n",
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, df.dtypes != 'object']\n",
    "df.drop('Id' , axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```We would like to predict the SalePrice columns. Create, using your data, the features dataset and the target dataset. Use sklearn.model_selection.train_test_split and create a train segment of 0.7 of your data and test segment of 0.3 of your data.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df.drop('SalePrice', axis=1)\n",
    "df_y = df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Try fitting the best linear regression you can (evaluate yourself using mean squared error). You can also use ridge regression with different alphas.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Ridge(alpha=3000)\n",
    "#clf = LinearRegression()\n",
    "clf.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```If you would look closely, you will find out that you dropped the columns LotShape and LandContour. This time try not dropping them, and instead replace them with a 1-hot encoding of them (consider``` [pandas.get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html))```.\n",
    "Try getting better results on the test segment using your ridge regressions. compare the new results with the old ones.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df_original.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_dum = pd.get_dummies(df_original, columns=['LotShape','LandContour'] , dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_dum.drop('Id' , axis=1 , inplace=True)\n",
    "df_with_dum = df_with_dum.loc[:, (df_with_dum.dtypes != 'object')  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df_with_dum.drop('SalePrice', axis=1)\n",
    "df_y = df_with_dum['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = Ridge(alpha=20)\n",
    "#clf = LinearRegression()\n",
    "clf.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "mean_squared_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Now add more features to your dataframe:```\n",
    "- ```LotArea in squared meters ( it's currently in units of squared feet)```\n",
    "- ```1stFlrSF + 2ndFlrSF```\n",
    "- ```GarageArea**0.5```\n",
    "- ```LotArea / (BedroomAbvGr+1)```\n",
    "- ```LotArea / (mean LotArea for houses built in that same year + 1e-5) - you might want to use``` [pandas merge function](https://www.google.com/search?q=pandas+merge&oq=pandas+merge&aqs=chrome..69i57l2j69i59l3j69i60.2080j0j9&sourceid=chrome&ie=UTF-8)\n",
    "- ```Ranking of LotArea (largest house has 1, the second largest has 2 and so on)```\n",
    "- ```One hot encoding of LotConfig```\n",
    "\n",
    "```Are they improve the results?.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_extend = df_original\n",
    "df_with_extend = df_original.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_extend = pd.get_dummies(df_with_extend, columns=['LotShape','LandContour','LotConfig'] , dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_extend.drop('Id' , axis=1 , inplace=True)\n",
    "df_with_extend = df_with_extend.loc[:, (df_with_extend.dtypes != 'object')  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_extend['LotArea_meter'] = df_with_extend['LotArea'] / 3.28084 # feet to meter\n",
    "df_with_extend['GarageArea'] = df_with_extend['GarageArea']**0.5\n",
    "df_with_extend['LB'] = df_with_extend['LotArea'] / (df_with_extend['BedroomAbvGr']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_area = pd.DataFrame(df_with_extend.groupby(['YearBuilt'])['LotArea'].mean()).reset_index()\n",
    "year_area.rename(columns={'LotArea' : 'LotAreaPerYear'} , inplace=True)\n",
    "df_with_extend = df_with_extend.merge(year_area , on='YearBuilt')\n",
    "df_with_extend['LotArea_mean_year'] = df_with_extend['LotArea'] / df_with_extend['LotAreaPerYear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_extend['LotArea_rank'] = df_with_extend['LotArea'].rank(method='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df_with_extend.drop('SalePrice', axis=1)\n",
    "df_y = df_with_extend['SalePrice']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = Ridge(alpha=50)\n",
    "#clf = LinearRegression()\n",
    "clf.fit(X_train , y_train)\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "mean_squared_error(y_test, y_test_pred) # didnt improve the result :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Think of a feature of your own that improve the result.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_extend['LotAreaMeter_divideByYear'] = df_with_extend['LotArea_meter']/df_with_extend['YearBuilt']\n",
    "df_with_extend['untillYearRemodAdd'] = df_with_extend['YearBuilt'] - df_with_extend['YearRemodAdd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Use KNN regression (sklearn.neighbors.KNeighborsRegressor).\n",
    "Compare the results to the linear regression.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "clf = KNeighborsRegressor(n_neighbors=4)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_with_extend.drop('SalePrice', axis=1), df_y, test_size=0.3, random_state=42)\n",
    "clf.fit(X_train , y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "mean_squared_error(y_test, y_test_pred) # didnt improve the result :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
